{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "import sys\n",
    "import keras.models\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Permute, Conv2D, MaxPooling2D, Flatten, Activation, Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD\n",
    "#import tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Andy/Andy/Undergrad/Year_1/uas/drone_code/src/vision/classifier\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "\n",
    "IMG_SIZE = 224\n",
    "\n",
    "def letter_seg(path):\n",
    "    #convert image to a numpy array\n",
    "    img = Image.open(path)\n",
    "    img = img.resize((IMG_SIZE,IMG_SIZE))\n",
    "    img = np.array(img).astype(np.float32)\n",
    "    Z = img.reshape(IMG_SIZE*IMG_SIZE,3)\n",
    "\n",
    "    #use k-means to convert image to 2 colors\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "    K = 2\n",
    "    ret,label,center=cv2.kmeans(Z,K,None,criteria,10,cv2.KMEANS_RANDOM_CENTERS)\n",
    "    center = np.uint8(center)\n",
    "    res = center[label.flatten()]\n",
    "    res2 = res.reshape((img.shape))\n",
    "\n",
    "    #convert the image to black and white\n",
    "    res2 = (res2 == res2[0,0]).astype(np.float32)\n",
    "\n",
    "    #create mask for floodfilling\n",
    "    h, w = res2.shape[:2]\n",
    "    mask = np.zeros((h+2, w+2), np.uint8)\n",
    "\n",
    "    #meant to close gaps but doesn't work well\n",
    "    #kernel = np.ones((14,14),np.uint8)\n",
    "    #res2 = cv2.morphologyEx(res2, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    #Floodfill from point (0, 0)\n",
    "    cv2.floodFill(res2, mask, (0,0), 0)\n",
    "    \n",
    "    return np.expand_dims(res2[:,:,0], axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading\n",
    "\n",
    "SHAPE_INDEX = [\n",
    "    'circle', 'cross', 'heptagon', 'octagon', 'pentagon', 'quarter_circle',\n",
    "    'rectangle', 'semicircle', 'star', 'trapezoid', 'triangle'\n",
    "]\n",
    "\n",
    "def shape_img(path):\n",
    "    img = Image.open(path)\n",
    "    img = img.resize((IMG_SIZE, IMG_SIZE))\n",
    "    #img = img.reshape((IMG_SIZE, IMG_SIZE))\n",
    "    img = np.array(img).astype(np.float32)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    return img\n",
    "\n",
    "def letter_img(path):\n",
    "    img = letter_seg(path)\n",
    "    img = cv2.resize(img, dsize=(32, 32), interpolation=cv2.INTER_LINEAR)\n",
    "    img = np.expand_dims(img, axis=2) \n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    return img\n",
    "\n",
    "def load_model(path):\n",
    "    return keras.models.load_model(path)\n",
    "\n",
    "def predict(model, img):\n",
    "    return np.argmax(model.predict(img))\n",
    "\n",
    "def predict_shape(model, img):\n",
    "    return SHAPE_INDEX[predict(model, img)]\n",
    "\n",
    "def predict_letter(model, img):\n",
    "    return chr(predict(model, img) + 65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "#letter_seg('../targets/output/train/00.jpg')\n",
    "img = shape_img('../targets/output/train/000.jpg')\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "\n",
    "def letter_model():\n",
    "    K.set_image_data_format( 'channels_last' )\n",
    "    model = Sequential()\n",
    "    model.add(Permute((1,2, 3), input_shape=(32, 32, 1)))\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=(5,5), activation='relu', kernel_initializer='TruncatedNormal', name=\"conv1\"))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "    model.add(Dropout(.25))\n",
    "\n",
    "    model.add(Conv2D(64, kernel_size=(5,5), activation='relu', kernel_initializer='TruncatedNormal', name=\"conv2\"))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "    model.add(Dropout(.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1600, activation='relu', name='fc3'))\n",
    "    model.add(Dense(26, activation='softmax', name='fc4'))\n",
    "    return model\n",
    "\n",
    "def shape_model():\n",
    "    K.set_image_data_format( 'channels_last' )\n",
    "    model = Sequential()\n",
    "    model.add(Permute((1,2,3), input_shape=(IMG_SIZE, IMG_SIZE, 3)))\n",
    "\n",
    "    model.add(Conv2D(64, kernel_size=(3,3), padding='same', activation='relu', name=\"conv1_1\"))\n",
    "    model.add(Conv2D(64, kernel_size=(3,3), padding='same', activation='relu', name=\"conv1_2\"))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(Conv2D(128, kernel_size=(3,3), padding='same', activation='relu', name=\"conv2_1\"))\n",
    "    model.add(Conv2D(128, kernel_size=(3,3), padding='same', activation='relu', name=\"conv2_2\"))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(Conv2D(256, kernel_size=(3,3), padding='same', activation='relu', name=\"conv3_1\"))\n",
    "    model.add(Conv2D(256, kernel_size=(3,3), padding='same', activation='relu', name=\"conv3_2\"))\n",
    "    model.add(Conv2D(256, kernel_size=(3,3), padding='same', activation='relu', name=\"conv3_3\"))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(Conv2D(512, kernel_size=(3,3), padding='same', activation='relu', name=\"conv4_1\"))\n",
    "    model.add(Conv2D(512, kernel_size=(3,3), padding='same', activation='relu', name=\"conv4_2\"))\n",
    "    model.add(Conv2D(512, kernel_size=(3,3), padding='same', activation='relu', name=\"conv4_3\"))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(Conv2D(512, kernel_size=(3,3), padding='same', activation='relu', name=\"conv5_1\"))\n",
    "    model.add(Conv2D(512, kernel_size=(3,3), padding='same', activation='relu', name=\"conv5_2\"))\n",
    "    model.add(Conv2D(512, kernel_size=(3,3), padding='same', activation='relu', name=\"conv5_3\"))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "    \n",
    "    model.add(Conv2D(4096, kernel_size=(7,7), activation='relu', name='fc6'))\n",
    "    model.add(Conv2D(4096, kernel_size=(1,1), activation='relu', name='fc7'))\n",
    "    model.add(Conv2D(13, kernel_size=(1,1),  name='fc8'))\n",
    "    model.add(Flatten())\n",
    "    model.add( Activation('softmax') )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.sequential.Sequential object at 0x118dc8da0>\n"
     ]
    }
   ],
   "source": [
    "model = shape_model()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "\n",
    "train_dir = '../targets/output/train/'\n",
    "test_dir = '../targets/output/test/'\n",
    "\n",
    "# def old_process_data(data_path, type=\"\"):\n",
    "#     if type == \"\":\n",
    "#         raise ValueError('Please input the type of data (shape or letter)')\n",
    "#     label_size = {\"shape\": 11, \"letter\": 26}\n",
    "#     f = tables.open_file(data_path, mode='r')\n",
    "#     x_train = f.root.train_input[()]\n",
    "#     y_train = f.root.train_labels[()]\n",
    "#     x_test = f.root.test_input[()]\n",
    "#     y_test = f.root.test_labels[()]\n",
    "#     f.close()\n",
    "#     y_train = to_categorical(y_train, label_size[type])\n",
    "#     y_test = to_categorical(y_test, label_size[type])\n",
    "#     return x_train, y_train, x_test, y_test\n",
    "\n",
    "def process_data(data_dir, n_images, feature=\"\", old=False):\n",
    "    if feature == \"\":\n",
    "        raise ValueError('Please input the type of data (shape or letter)')\n",
    "    label_size = {\"shape\": 13, \"letter\": 36}\n",
    "    if old:\n",
    "        label_size = {\"shape\": 11, \"letter\": 26}\n",
    "    img_size = {\"shape\": (IMG_SIZE, IMG_SIZE, 3), \"letter\": (32, 32, 1)}\n",
    "    label_col = {\"shape\": 5, \"letter\": 6}\n",
    "    img_func = {\"shape\": shape_img, \"letter\": letter_img}\n",
    "    # Load data from data_dir\n",
    "    x_train = np.zeros((n_images,) + img_size[feature])\n",
    "    path = os.path.join(data_dir, 'labels.csv')\n",
    "    labels = np.loadtxt(path, delimiter=',')\n",
    "    y_train = labels[0:n_images, label_col[feature]]\n",
    "    for i in range(n_images):\n",
    "        path = os.path.join(data_dir, '%03d.jpg'%i)\n",
    "        x_train[i] = img_func[feature](path)[0,:]\n",
    "    y_train = to_categorical(y_train, label_size[feature])\n",
    "    return x_train, y_train\n",
    "\n",
    "def get_train_and_test(feature, n_train, n_test):\n",
    "    (x_train, y_train) = process_data(train_dir, n_train, feature)\n",
    "    (x_test, y_test) = process_data(test_dir, n_test, feature)\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 224, 224, 3) (1000, 13) (200, 224, 224, 3) (200, 13)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train, x_test, y_test) = get_train_and_test(\"shape\", 1000, 200)\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, x_train, y_train, x_test, y_test, nEpochs=10, nBatch=32, model_name=\"model\"):\n",
    "    sgd = SGD(lr=0.0001)\n",
    "    model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(x=x_train, y=y_train, batch_size=nBatch, epochs=nEpochs, verbose=1)\n",
    "    model.evaluate(x=x_test, y=y_test, verbose=1)\n",
    "#     model.save(model_name + '.hdf5')\n",
    "    return model\n",
    "\n",
    "# def process_letter(addr):\n",
    "#     img = Image.open(addr).convert('L')\n",
    "#     img = img.reshape((32,32))\n",
    "#     img = np.array(img).astype(np.float32)\n",
    "#     img = np.expand_dims(img, axis=0)\n",
    "#     img = np.expand_dims(img, axis=3)\n",
    "#     return img\n",
    "\n",
    "# def process_shape(addr):\n",
    "#     img = Image.open(addr).convert('L')\n",
    "#     img = img.reshape((IMG_SIZE,IMG_SIZE))\n",
    "#     img = np.array(img).astype(np.float32)\n",
    "#     img = np.expand_dims(img, axis=0)\n",
    "    \n",
    "def predict(model, img):\n",
    "    return model.predict(img)\n",
    "\n",
    "def predict_shape(model, img):\n",
    "    return SHAPE_INDEX[predict(model, img).argmax()]\n",
    "\n",
    "def predict_letter(model, img):\n",
    "    return chr(predict(model, img).argmax() + 65)\n",
    "\n",
    "def load_model(path):\n",
    "    return keras.models.load_model(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = process_letter('../targets/output/train/00.jpg')\n",
    "# print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = train(model, x_train, y_train, x_test, y_test)\n",
    "#model.evaluate(x=x_test, y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_model = load_model('../models/shape/shape_model.h5')\n",
    "letter_model = load_model('../models/letter/letter_model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 224, 224, 3) (1000, 11) (1000, 32, 32, 1) (1000, 26)\n"
     ]
    }
   ],
   "source": [
    "old_dir = '../targets/output/old'\n",
    "xs_old, ys_old = process_data(old_dir, 1000, 'shape', True)\n",
    "xl_old, yl_old = process_data(old_dir, 1000, 'letter', True)\n",
    "print(xs_old.shape, ys_old.shape, xl_old.shape, yl_old.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 497s 497ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.9609717235565185, 0.567]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape_model.evaluate(x=xs_old, y=ys_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 571us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.2565239391326903, 0.051]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letter_model.evaluate(x=xl_old, y=yl_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.1036822e-14 8.1971246e-10 1.9073529e-14 7.5558510e-14 4.8644341e-13\n",
      "  2.2895628e-09 4.6307811e-09 3.5275571e-10 6.1940984e-04 3.9877923e-06\n",
      "  9.9937660e-01]]\n",
      "predicted:  triangle\n",
      "true:  star\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "path = '../targets/output/old/%03d.jpg'%i\n",
    "print(predict(shape_model, shape_img(path)))\n",
    "print('predicted: ', predict_shape(shape_model, shape_img(path)))\n",
    "print('true: ', SHAPE_INDEX[ys_old[i].argmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.03908519 0.03751915 0.03880334 0.03896307 0.0377778  0.03828578\n",
      "  0.03784261 0.03847403 0.0380136  0.0390711  0.03903157 0.03835811\n",
      "  0.03882906 0.03845845 0.0384722  0.03802907 0.03949932 0.03904926\n",
      "  0.03757166 0.03841253 0.03854285 0.03849417 0.03924222 0.03855116\n",
      "  0.03734707 0.03827557]]\n",
      "predicted:  Q\n",
      "true:  U\n"
     ]
    }
   ],
   "source": [
    "print(predict(letter_model, letter_img(path)))\n",
    "print('predicted: ', predict_letter(letter_model, letter_img(path)))\n",
    "print('true: ', chr(yl_old[i].argmax() + 65))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
